Metadata-Version: 2.1
Name: tridu33ml
Version: 0.0.1
Summary: tridu33 Learn Write ML Frame
Home-page: UNKNOWN
Author: Tridu33
Author-email: tridu33@qq.com
License: UNKNOWN
Platform: UNKNOWN
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown



tridu33 Learn Write a Machine learning framework:.

it is a Coursework in kaikeba .

after ` pip install tridu33ml`,then `pip list`this is a test about Boston price: 

```python
#boston.py
import numpy as np
from sklearn.datasets import load_boston
from sklearn.utils import shuffle, resample
#from miniflow import *

# Load data
data = load_boston()
X_ = data['data']
y_ = data['target']

# Normalize data
X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)

n_features = X_.shape[1]
n_hidden = 10
W1_ = np.random.randn(n_features, n_hidden)
b1_ = np.zeros(n_hidden)
W2_ = np.random.randn(n_hidden, 1)
b2_ = np.zeros(1)


from tridu33ml.nn import core
from tridu33ml.utils import utilities
# Neural network
X, y = core.Placeholder(), core.Placeholder()
W1, b1 = core.Placeholder(), core.Placeholder()
W2, b2 = core.Placeholder(), core.Placeholder()

l1 = core.Linear(X, W1, b1)
s1 = core.Sigmoid(l1)
l2 = core.Linear(s1, W2, b2)
cost = core.MSE(y, l2)

feed_dict = {
    X: X_,
    y: y_,
    W1: W1_,
    b1: b1_,
    W2: W2_,
    b2: b2_
}

epochs = 5000
# Total number of examples
m = X_.shape[0]
batch_size = 16
steps_per_epoch = m // batch_size

graph = utilities.topological_sort_feed_dict(feed_dict)
trainables = [W1, b1, W2, b2]

print("Total number of examples = {}".format(m))



losses = []

for i in range(epochs):
    loss = 0
    for j in range(steps_per_epoch):
        # Step 1
        # Randomly sample a batch of examples
        X_batch, y_batch = resample(X_, y_, n_samples=batch_size)

        # Reset value of X and y Inputs
        X.value = X_batch
        y.value = y_batch

        # Step 2
        _ = None
        utilities.forward_and_backward(graph) # set output node not important.

        # Step 3
        rate = 1e-2

        utilities.optimize(trainables, rate)

        loss += graph[-1].value

    if i % 100 == 0: 
        print("Epoch: {}, Loss: {:.3f}".format(i+1, loss/steps_per_epoch))
        losses.append(loss/steps_per_epoch)



```

 run the test :

```
python boston.py
```

then you will see the training result.


