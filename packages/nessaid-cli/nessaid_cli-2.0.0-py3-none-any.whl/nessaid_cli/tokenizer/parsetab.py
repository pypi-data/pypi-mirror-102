
# parsetab.py
# This file is automatically generated. Do not edit.
# pylint: disable=W,C,R
_tabversion = '3.10'

_lr_method = 'LALR'

_lr_signature = 'QUOTED_INCOMPLETE_STR QUOTED_STR TEXTline_content : line emptyline : line segment\n                | emptysegment : text\n                   | quoted_string\n                   | incomplete_quoted_stringquoted_string : QUOTED_STRincomplete_quoted_string : QUOTED_INCOMPLETE_STRtext : TEXTempty :'
    
_lr_action_items = {'TEXT':([0,2,3,5,6,7,8,9,10,11,],[-10,9,-3,-2,-4,-5,-6,-9,-7,-8,]),'QUOTED_STR':([0,2,3,5,6,7,8,9,10,11,],[-10,10,-3,-2,-4,-5,-6,-9,-7,-8,]),'QUOTED_INCOMPLETE_STR':([0,2,3,5,6,7,8,9,10,11,],[-10,11,-3,-2,-4,-5,-6,-9,-7,-8,]),'$end':([0,1,2,3,4,5,6,7,8,9,10,11,],[-10,0,-10,-3,-1,-2,-4,-5,-6,-9,-7,-8,]),}

_lr_action = {}
for _k, _v in _lr_action_items.items():
   for _x,_y in zip(_v[0],_v[1]):
      if not _x in _lr_action:  _lr_action[_x] = {}
      _lr_action[_x][_k] = _y
del _lr_action_items

_lr_goto_items = {'line_content':([0,],[1,]),'line':([0,],[2,]),'empty':([0,2,],[3,4,]),'segment':([2,],[5,]),'text':([2,],[6,]),'quoted_string':([2,],[7,]),'incomplete_quoted_string':([2,],[8,]),}

_lr_goto = {}
for _k, _v in _lr_goto_items.items():
   for _x, _y in zip(_v[0], _v[1]):
       if not _x in _lr_goto: _lr_goto[_x] = {}
       _lr_goto[_x][_k] = _y
del _lr_goto_items
_lr_productions = [
  ("S' -> line_content","S'",1,None,None,None),
  ('line_content -> line empty','line_content',2,'p_line_content','tokenizer.py',75),
  ('line -> line segment','line',2,'p_line','tokenizer.py',80),
  ('line -> empty','line',1,'p_line','tokenizer.py',81),
  ('segment -> text','segment',1,'p_segment','tokenizer.py',91),
  ('segment -> quoted_string','segment',1,'p_segment','tokenizer.py',92),
  ('segment -> incomplete_quoted_string','segment',1,'p_segment','tokenizer.py',93),
  ('quoted_string -> QUOTED_STR','quoted_string',1,'p_quoted_string','tokenizer.py',98),
  ('incomplete_quoted_string -> QUOTED_INCOMPLETE_STR','incomplete_quoted_string',1,'p_incomplete_quoted_string','tokenizer.py',102),
  ('text -> TEXT','text',1,'p_text','tokenizer.py',106),
  ('empty -> <empty>','empty',0,'p_empty','tokenizer.py',111),
]
